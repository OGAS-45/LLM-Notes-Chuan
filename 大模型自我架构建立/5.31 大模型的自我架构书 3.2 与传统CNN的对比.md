1. **CNN 的局部特征提取**
     * **卷积操作原理** ：CNN（卷积神经网络）主要通过卷积层来提取局部特征。卷积层包含多个卷积核（滤波器），这些卷积核在图像上滑动，对图像的局部区域进行加权求和操作。例如，一个 3×3 的卷积核在 224×224 的图像上滑动，每次对 3×3 的像素区域进行线性组合。这个过程可以看作是在提取图像的局部特征，如边缘、纹理等。假设卷积核的参数是 \([w_{1},w_{2},...,w_{9}]\)，对于图像的一个 3×3 小块像素值 \([x_{1},x_{2},...,x_{9}]\)，卷积操作后的结果为 \(y = \sum_{i = 1}^{9}w_{i}x_{i} + b\)（其中 \(b\) 是偏置项）。通过这种方式，卷积核能够捕捉到局部像素之间的空间关系。
     * **池化操作作用** ：池化层（如最大池化、平均池化）通常位于卷积层之后，其主要作用是降低特征图的空间尺寸，同时保留重要信息。例如，最大池化是在一个局部区域内取最大值，这可以减少计算量，并且在一定程度上使特征具有平移不变性。以 2×2 的最大池化为例，将 2×2 的像素区域替换为该区域的最大值，这样可以降低特征图的分辨率，但保留了图像的主要特征结构。
     * **逐步构建全局特征** ：CNN 通过多层卷积和池化操作，从局部特征逐步构建全局特征。最初几层的卷积层主要提取低级的局部特征，如边缘、颜色等。随着网络深度的增加，后面的卷积层可以提取更高级的语义特征，如物体的部件、形状等。这些高级特征是通过前面层级提取的局部特征组合而成的，从而逐步构建出图像的全局特征。

  2. **ViT 的全局依赖捕捉**
     * **图像分割和线性投影** ：ViT（Vision Transformer）首先将图像分割成多个固定大小的非重叠图像块。例如，将一张 224×224 的图像分割成 16×16 的小块，每个小块可以看作是一个 “标记”，就像 NLP 中的单词一样。然后将每个图像块展开成一维向量，通过线性变换将其映射到一个固定维度的嵌入空间，得到每个图像块的嵌入表示。这一步相当于将图像转换为一种序列格式，使其能够输入到 Transformer 架构中。



     * **位置编码的添加** ：由于 Transformer 架构本身不包含位置信息，所以需要为每个图像块的嵌入表示添加位置编码。位置编码可以是正弦位置编码或可学习位置编码。位置编码的作用是让模型能够知道每个图像块在图像中的空间位置关系。例如，在正弦位置编码中，不同位置的编码在不同的维度上按照正弦函数和余弦函数的方式变化，这样模型就可以根据这些编码来区分不同位置的图像块。
     * **自注意力机制的工作原理** ：将添加了位置编码的图像块嵌入序列输入到 Transformer 编码器中，编码器中的自注意力层是关键部分。自注意力机制计算每个图像块嵌入与其他所有图像块嵌入之间的关系。具体来说，对于每个图像块嵌入 \(Q\)（查询向量），会与所有图像块嵌入 \(K\)（键向量）进行点积操作，得到注意力分数，表示它们之间的相关性。然后通过softmax 函数将这些分数转换为概率分布，再与对应的图像块嵌入 \(V\)（值向量）进行加权求和，得到新的嵌入表示。这个过程可以表示为 \(Attention(Q,K,V) = softmax(\frac{QK^{T}}{\sqrt{d_{k}}})V\)，其中 \(d_{k}\) 是键向量的维度。自注意力机制使得每个图像块都能够与其他所有图像块进行信息交互，从而捕捉到图像块之间的全局依赖关系。

总的来说，CNN 主要是通过局部卷积操作提取局部特征，再通过池化和多层结构逐步构建全局特征；而 ViT 是将图像分割成块后，利用自注意力机制直接捕捉图像块之间的全局依赖关系。


Vision Transformer（ViT）和Convolutional Neural Network（CNN）在计算机视觉领域各有优劣，以下是对它们的详细分析：

### ViT 的优劣势
**优势**：
- **全局信息捕获能力强**：ViT通过自注意力机制，能够直接捕捉图像块之间的全局依赖关系。这对于理解图像的整体结构和语义非常有效，例如在图像分类任务中，ViT可以更好地理解图像中不同部分之间的关系，从而提高分类的准确性。
- **可扩展性强**：ViT的架构相对简单，易于扩展。可以通过增加Transformer编码器的层数、增大嵌入维度等方式来提升模型的容量和性能。此外，ViT还可以很容易地与其他技术（如混合注意力机制、多尺度特征提取等）结合，以进一步提高模型的效果。
- **在大规模数据集上表现优异**：当有足够的训练数据时，ViT能够学习到更丰富的特征表示。在像ImageNet-21k等大规模数据集上预训练的ViT模型，在各种下游任务中都取得了非常出色的成绩。

**劣势**：
- **计算复杂度高**：ViT的自注意力机制计算复杂度与图像块的数量呈二次关系。对于高分辨率的图像，图像块数量会大幅增加，导致计算成本急剧上升。这使得ViT在处理大规模图像数据时需要更高的计算资源和更长的训练时间。
- **对小规模数据集不友好**：ViT通常需要大规模的数据集进行预训练才能发挥其性能优势。在小规模数据集上，ViT容易出现过拟合现象，而且其性能可能不如经过精心设计的CNN架构。
- **模型泛化能力受限于预训练数据**：ViT的性能在很大程度上依赖于预训练数据的多样性和质量。如果预训练数据与目标任务的数据分布差异较大，ViT的泛化能力可能会受到影响。

### CNN 的优劣势
**优势**：
- **局部特征提取能力强**：CNN通过卷积操作能够有效地提取图像的局部特征，如边缘、纹理等。这些局部特征对于许多计算机视觉任务（如目标检测、语义分割等）非常重要，因为它们可以帮助模型更好地理解和定位图像中的物体。
- **计算效率高**：CNN的卷积操作具有局部感受野和参数共享的特性，这使得它在计算上相对高效。对于相同规模的模型，CNN通常比ViT具有更快的推理速度和更低的计算成本，特别是在处理高分辨率图像时。
- **对小规模数据集适应性好**：CNN可以通过数据增强、正则化等技术在小规模数据集上取得较好的性能。其局部特征提取能力使其在小数据集上也能学习到有效的特征表示，而不易出现过拟合现象。

**劣势**：
- **全局信息捕获能力有限**：CNN主要依赖于局部卷积操作和池化操作来逐步构建全局特征，这可能导致它在捕获图像的全局语义信息方面存在一定的局限性。在一些需要全局理解的任务（如图像分类）上，CNN可能不如ViT能够充分利用图像的整体信息。
- **模型深度和复杂度受限**：随着CNN模型深度的增加，梯度消失和梯度爆炸等问题可能会变得更加严重，这限制了模型的进一步深化和性能提升。虽然一些技术（如残差连接、批归一化等）可以在一定程度上缓解这些问题，但仍然无法完全解决。
- **对尺度变化敏感**：CNN的卷积核大小和池化操作通常是在训练前固定好的，这使得它对图像的尺度变化较为敏感。如果图像中物体的尺度与训练时的尺度差异较大，CNN的性能可能会受到影响。

ViT在全局信息捕获和大规模数据处理方面具有优势，而CNN则在局部特征提取、计算效率和小规模数据适应性方面表现出色。在实际应用中，可以根据具体任务和数据特点选择合适的模型，或者探索融合ViT和CNN优势的混合架构，以取得更好的效果。
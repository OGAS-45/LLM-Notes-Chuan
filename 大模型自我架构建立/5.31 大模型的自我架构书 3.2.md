Vision Transformer（ViT）架构是一种将 Transformer 架构从处理序列数据扩展到处理图像数据的模型，在计算机视觉领域应用广泛。以下是相关介绍：

### ViT 将 Transformer 架构扩展到图像数据的方式

  * **图像分割** ：ViT 将输入图像分割成多个固定大小的非重叠图像块，如将一张 224x224 的图像分割成 16x16 的小块，每个小块可以看作是一个 “单词” 或 “标记”，这类似于 NLP 中将句子分割成单词或标记。
  * **线性投影** ：将每个图像块展开成一维向量，然后通过线性变换将这些向量映射到一个固定维度的嵌入空间，得到每个图像块的嵌入表示，这相当于 NLP 中的词嵌入操作。
  * **添加位置编码** ：由于 Transformer 架构本身不包含位置信息，因此需要为每个图像块的嵌入表示添加位置编码，以告知模型图像块在图像中的空间位置关系，常见的位置编码方式包括正弦位置编码、可学习位置编码等。
  * **Transformer 编码器处理** ：将添加了位置编码的图像块嵌入序列输入到 Transformer 编码器中，编码器由多个自注意力层和前馈神经网络层组成。自注意力机制使每个图像块能够与其他所有图像块进行信息交互，从而捕获图像中的全局依赖关系。

### ViT 与其他图像处理模型的对比

  * **与传统 CNN 的对比** ：
    * **架构差异** ：==CNN 主要通过卷积层和池化层来提取图像的局部特征，再逐步构建出图像的全局特征。而 ViT 直接将图像分割成块，将图像块序列输入 Transformer 编码器，利用自注意力机制捕捉图像块之间的全局依赖关系。==

[[5.31 大模型的自我架构书 3.2 与传统CNN的对比]]

    * **特征提取能力** ：CNN 在提取局部特征方面表现出色，能够有效地捕捉图像中的边缘、纹理等细节信息。ViT 则更擅长捕捉图像的全局语义信息，对于需要理解图像整体结构和关系的任务，如图像分类、目标检测等，具有一定的优势。
    * **数据需求** ：CNN 由于具有局部感受野和共享权重等特性，对小规模数据集具有较好的泛化能力。相比之下，ViT 需要大规模的数据集进行预训练，才能充分学习到图像的全局特征和模式。
    * **计算复杂度** ：CNN 的计算复杂度主要取决于卷积核的大小、卷积层的层数等因素，对于大规模图像数据，计算效率相对较高。ViT 中的自注意力机制计算复杂度与图像块的数量呈二次关系，当图像块数量较多时，计算复杂度会急剧上升，需要更高的计算资源。

  * **与其他基于 Transformer 的图像处理模型对比** ：
    * **DeiT（Data-efficient Image Transformer）** ：DeiT 在 ViT 的基础上引入了 distilled vision transformer（DeiT）架构，通过添加一个 distillation token 来提高模型在小规模数据集上的性能。此外，DeiT 还采用了一系列数据增强和正则化技术，如 Mixup、CutMix 等，以进一步提高模型的泛化能力。
    * **Swin Transformer** ：Swin Transformer 是一种层次化的 Transformer 架构，它将图像划分为多个不重叠的窗口，并在窗口内进行自注意力计算，然后通过窗口间的特征交互来构建层次化的特征图。与 ViT 相比，Swin Transformer 在计算效率和模型性能之间取得了更好的平衡。
    * **CvT（Cross ViT）** ：CvT 通过引入跨视图Transformer模块，将不同尺度的图像特征进行融合，从而更好地捕捉图像的多尺度信息。相比之下，ViT 主要关注于单尺度图像块的处理。